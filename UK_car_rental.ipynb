{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eba6c4d-4924-4c2c-a612-1749f77b9f3f",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center; \">Descriptive Title</h1>\n",
    "<h2 style = \"text-align: center; \">ST445 - Managing and Visualizing Data</h2>\n",
    "<h3 style = \"text-align: center; \">Candidate IDs: 38682, XXXXX, YYYYY</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d0cd6-41d5-411e-9b4b-77c036095efd",
   "metadata": {},
   "source": [
    "### I. Notebook preparation (maybe this section is not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d924202-119e-4f3b-a3e9-86b75f4cf4db",
   "metadata": {},
   "source": [
    "Perhaps we include something similar to this example from \"Example 2\"\n",
    "\n",
    "[[Before running this notebook, please make sure you have all necessary modules installed in your environment. Potentially less common modules used include:\n",
    "\n",
    "google.cloud\n",
    "dotenv\n",
    "networkx\n",
    "geopandas\n",
    "praw\n",
    "transformers\n",
    "plotly.graph_objects\n",
    "ipywidgets\n",
    "folium\n",
    "As usual, they can be installed by running the command pip install [module] in the terminal.\n",
    "\n",
    "Furthermore, please make sure your Python version is compatible with all the modules. While writing this, it became apparent there might be some compatibility issues with newer Python versions (especially 3.11 and newer). In case you run into any issues, it might be worth trying to run the code with an older version such as Python 3.9.]]\n",
    "\n",
    "Our complete GitHub repository can be found at the following location: https://github.com/lse-st445/2024-project-data-knows-ball [[Should we put this in the title of our paper??]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ab781c0-3872-4e8b-be19-75cac3339c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Install lxml with conda install anaconda::lxml to use HMTL and XML with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25976ea8-9e39-4992-a392-dcfa15bcaf01",
   "metadata": {},
   "source": [
    "### II. Introduction and data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c356341-6578-4865-a830-245d6900b7cc",
   "metadata": {},
   "source": [
    "[[Describe our data sets and pose our research question]]\n",
    "\n",
    "[[Maybe include data dictionaries of some sort similar to Table 1.3.1 and Table 1.3.2 in \"Example 2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e41b65-18f2-4643-9555-b1f698c5c164",
   "metadata": {},
   "source": [
    "### III. Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633420d-5e46-4d1f-927d-4ec746fcc7d4",
   "metadata": {},
   "source": [
    "#### III.i. Marketcheck UK API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1894046-b835-4bb2-952f-a6d1abeee430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a99d94-2a62-4661-92a4-f981b889bbb6",
   "metadata": {},
   "source": [
    "#### III.ii. Webscrapping UK Office of National Statistics (ONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25aaf25-97af-45fa-a3e0-11ed7d957874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function for webscrapping data from the UK Office of National Statistics\n",
    "def webscrape_ONS(url):\n",
    "    '''\n",
    "    This function webscrapes various tables from the UK ONS and seperates the data \n",
    "    into distinct dataframes based on the given periodicity: year, quarter, or month.\n",
    "    ----------\n",
    "    Args:\n",
    "        url: The UK Office of National Statistics url from which to webscrabe the table\n",
    "    ----------\n",
    "    Returns:        \n",
    "        ons_year_df: Dataframe of UK ONS data at the yearly level\n",
    "        ons_quarter_df: Dataframe of UK ONS data at the quarterly level\n",
    "        ons_month_df: Dataframe of UK ONS data at the monthly level\n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    # Save the table headers to later set as column names for the dataframes\n",
    "    table_headers = soup.find_all(\"th\")\n",
    "    table_headers = table_headers[0:2] # We only need the first two columns of data from the ONS\n",
    "    table_headers = [t.text for t in table_headers]\n",
    "\n",
    "    ons_data = []\n",
    "\n",
    "    # Identify and append all webscrapped rows of the ONS table into a dataframe\n",
    "    for i, row in enumerate(soup.find_all(\"tr\")[2:]): # The frist two rows of ONS tables are headers\n",
    "        try:\n",
    "            period, value = row.find_all(\"td\")[0:2] # We only need the first two columns of data from the ONS\n",
    "            ons_data.append([period.text, value.text])\n",
    "        except:\n",
    "            print(\"Error parsing row #{}\".format(i))\n",
    "\n",
    "    ons_df = pd.DataFrame(ons_data, columns = table_headers)\n",
    "\n",
    "    # Split the data into separate dataframes based on periodicity (year/quarter/month)\n",
    "    ons_year_df = ons_df[ons_df[\"Period\"].str.len() == 4].reset_index(drop = True) # Year periods will have 4 characters (e.g., \"2020\")\n",
    "    ons_quarter_df = ons_df[ons_df[\"Period\"].str.len() == 7].reset_index(drop = True) # Quarter periods will have 7 characters (e.g., \"2020 Q1\")\n",
    "    ons_month_df = ons_df[ons_df[\"Period\"].str.len() == 8].reset_index(drop = True) # Month periods will have 8 characters (e.g., \"2020 JAN\")\n",
    "    \n",
    "    # Ensure that all rows present in the original ONS table are present in the three dataframes split based on periodicity\n",
    "    split_df_len = sum([len(ons_year_df), len(ons_quarter_df), len(ons_month_df)])\n",
    "    orig_df_len = len(ons_data)\n",
    "    assert split_df_len == orig_df_len, \"ERROR: Not all rows from original ONS table present in corresponding year/quarter/month dataframes\"\n",
    "\n",
    "    return ons_year_df, ons_quarter_df, ons_month_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "775f5de9-3fd2-4334-984c-7ed07896f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrape UK unemployment and CPIH data tables from the ONS\n",
    "url_uk_unemp = \"https://www.ons.gov.uk/employmentandlabourmarket/peoplenotinwork/unemployment/timeseries/mgsx/lms\"\n",
    "url_uk_cpih = \"https://www.ons.gov.uk/economy/inflationandpriceindices/timeseries/l55o/mm23\"\n",
    "\n",
    "uk_unemp_year_df, uk_unemp_quarter_df, uk_unemp_month_df = webscrape_ONS(url_uk_unemp)\n",
    "uk_cpih_year_df, uk_cpih_quarter_df, uk_cpih_month_df = webscrape_ONS(url_uk_cpih)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfe0b46e-3d1e-43ad-b690-c4121d7d0477",
   "metadata": {},
   "source": [
    "Quote on what CPIH entails: https://moneyweek.com/economy/inflation/605602/cpi-inflation-vs-rpi-inflation#:~:text=CPIH%20is%20another%20related%20measure,and%20living%20in%20a%20home.\n",
    "\n",
    "\"CPIH is another related measure calculated by the ONS. It stands for the Consumer Prices Index including owner occupiersâ€™ housing costs. It came in at 3.2% in October.\n",
    "\n",
    "CPIH is similar to CPI, but includes the costs of owning, maintaining and living in a home. This means it also shares characteristics with RPI.\n",
    "\n",
    "CPIH is the ONS's best measure of UK inflation given it captures more of the economy than the other two measures. However, given the UK housing system is different to that of any other nation, it is not internationally comparable.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a6c25-aa77-464b-b33a-0a2bc0e29c75",
   "metadata": {},
   "source": [
    "#### III.iii. US Bureau of Labor Statistics (BLS) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1654855d-5b5c-484c-ab41-7c34dfaea84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the BLS API for the following two datasets between the years of 2019-2024\n",
    "    # LNS14000000: The USA U-3 unemployment rate (\"official rate\"); civilian unemployment rate for 16 years and older, seasonally adjusted\n",
    "        # https://data.bls.gov/timeseries/LNS14000000\n",
    "    # CUUR0000SA0: CPI - All items in U.S. city average, all urban consumers, not seasonally adjusted\n",
    "        # https://data.bls.gov/timeseries/CUUR0000SA0\n",
    "# We are interested in retaining the last 5 years (2020-2024) of data. The reason for including 2019, is so that we can compute the YoY CPI percentage change\n",
    "# NOTE: because we have not registered we can only querry this API 25 times per day\n",
    "headers = {'Content-type': 'application/json'}\n",
    "data = json.dumps({\"seriesid\": ['LNS14000000', 'CUUR0000SA0'], \"startyear\": \"2019\", \"endyear\": \"2024\"})\n",
    "p = requests.post('https://api.bls.gov/publicAPI/v1/timeseries/data/', data = data, headers = headers)\n",
    "json_data = json.loads(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5273416a-1b5b-4aad-b24c-de778aa4c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the BLS unemployment and CPI data within a dataframe\n",
    "bls_data = []\n",
    "\n",
    "# NOTE: this code is heavily derived from the BLS API Version 1.0 Python Sample Code\n",
    "    # https://www.bls.gov/developers/api_python.htm\n",
    "for series in json_data['Results']['series']:\n",
    "    seriesId = series['seriesID']\n",
    "    for item in series['data']:\n",
    "        year = item['year']\n",
    "        period = item['period']\n",
    "        value = item['value']\n",
    "\n",
    "        if 'M01' <= period <= 'M12':\n",
    "            bls_data.append([seriesId,year,period,value])\n",
    "\n",
    "bls_df = pd.DataFrame(bls_data, columns = [\"SeriesID\", \"Year\", \"Period\", \"Value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d841970-b62c-46d4-a595-4b555b0d103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate BLS table into unemployment and CPI dataframes\n",
    "unemp_df = bls_df[bls_df[\"SeriesID\"] == \"LNS14000000\"].reset_index(drop = True)\n",
    "cpi_df = bls_df[bls_df[\"SeriesID\"] == \"CUUR0000SA0\"].reset_index(drop = True)\n",
    "\n",
    "# Ensure that all rows present in the original BLS table are present in the two split unemployment and CPI dataframes\n",
    "split_df_len = sum([len(unemp_df), len(cpi_df)])\n",
    "orig_df_len = len(bls_df)\n",
    "assert split_df_len == orig_df_len, \"ERROR: Not all rows from original BLS table present in corresponding unemployment and CPI dataframes\"\n",
    "\n",
    "# Clean the BLS unemployment data\n",
    "unemp_df.drop(\"SeriesID\", axis = 1, inplace = True)\n",
    "unemp_df = unemp_df.astype({\"Year\": int, \"Value\": float})\n",
    "\n",
    "# Clean the BLS CPI data\n",
    "cpi_df.drop(\"SeriesID\", axis = 1, inplace = True)\n",
    "cpi_df = cpi_df.astype({\"Year\": int, \"Value\": float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6394e929-e923-4236-8964-4214386b6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in the previous 5 years of US BLS unemployment data (this is at the monthly level)\n",
    "us_unemp_month_df = unemp_df[unemp_df[\"Year\"] > 2019].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f3b91425-feb9-4eb4-af5b-261c6894094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure BLS CPI data to compute year-over-year values\n",
    "cpi_df_wide = cpi_df.pivot(index = \"Year\", columns = \"Period\", values = \"Value\").pct_change(fill_method = None).reset_index()\n",
    "cpi_df_long = pd.melt(cpi_df_wide, id_vars = [\"Year\"], value_vars = [\"M01\", \"M02\", \"M03\", \"M04\", \"M05\", \"M06\", \"M07\", \"M08\", \"M09\", \"M10\", \"M11\", \"M12\"])\n",
    "\n",
    "# We are only interested in the previous 5 years of US BLS CPI data (this is at the monthly level)\n",
    "us_cpi_month_df = cpi_df_long.dropna().reset_index(drop = True)\n",
    "us_cpi_month_df[\"Value\"] = us_cpi_month_df[\"value\"] * 100\n",
    "us_cpi_month_df.drop(\"value\", axis = 1, inplace = True)\n",
    "us_cpi_month_df = us_cpi_month_df.sort_values([\"Year\", \"Period\"], ascending = False).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0fb56-5ba7-4f25-afa4-df17f1e86799",
   "metadata": {},
   "source": [
    "### IV. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bb0f79-3825-4034-be04-27360a6955f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and merge datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a9d01-0703-4251-b108-c4a8ae9601b2",
   "metadata": {},
   "source": [
    "### V. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f89a6-87ef-48d3-9213-46f2fd3813a6",
   "metadata": {},
   "source": [
    "[[Description of what visualizations we decided to include and why]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2189e31b-d035-4aa3-9d7c-b23607a1e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc481e82-e40a-452c-9beb-9be59b4445da",
   "metadata": {},
   "source": [
    "[[Explanation/interpretation of the visualizations are depicting]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bc21b-107e-44fd-82f0-29a33415595b",
   "metadata": {},
   "source": [
    "### VI. Data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f8b78-c8a2-41c7-b185-410741ebb525",
   "metadata": {},
   "source": [
    "### VII. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dec5a6-42e8-437e-a2e3-54d242af6a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
