{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eba6c4d-4924-4c2c-a612-1749f77b9f3f",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center; \">Descriptive Title</h1>\n",
    "<h2 style = \"text-align: center; \">ST445 - Managing and Visualizing Data</h2>\n",
    "<h3 style = \"text-align: center; \">Candidate IDs: 38682, 50450, YYYYY</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d0cd6-41d5-411e-9b4b-77c036095efd",
   "metadata": {},
   "source": [
    "### I. Notebook preparation (maybe this section is not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d924202-119e-4f3b-a3e9-86b75f4cf4db",
   "metadata": {},
   "source": [
    "Perhaps we include something similar to this example from \"Example 2\"\n",
    "\n",
    "[[Before running this notebook, please make sure you have all necessary modules installed in your environment. Potentially less common modules used include:\n",
    "\n",
    "google.cloud\n",
    "dotenv\n",
    "networkx\n",
    "geopandas\n",
    "praw\n",
    "transformers\n",
    "plotly.graph_objects\n",
    "ipywidgets\n",
    "folium\n",
    "As usual, they can be installed by running the command pip install [module] in the terminal.\n",
    "\n",
    "Furthermore, please make sure your Python version is compatible with all the modules. While writing this, it became apparent there might be some compatibility issues with newer Python versions (especially 3.11 and newer). In case you run into any issues, it might be worth trying to run the code with an older version such as Python 3.9.]]\n",
    "\n",
    "Our complete GitHub repository can be found at the following location: https://github.com/lse-st445/2024-project-data-knows-ball [[Should we put this in the title of our paper??]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3ab781c0-3872-4e8b-be19-75cac3339c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Install lxml with conda install anaconda::lxml to use HMTL and XML with Python\n",
    "# conda install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25976ea8-9e39-4992-a392-dcfa15bcaf01",
   "metadata": {},
   "source": [
    "### II. Introduction and data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c356341-6578-4865-a830-245d6900b7cc",
   "metadata": {},
   "source": [
    "[[Describe our data sets and pose our research question]]\n",
    "\n",
    "[[Maybe include data dictionaries of some sort similar to Table 1.3.1 and Table 1.3.2 in \"Example 2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e41b65-18f2-4643-9555-b1f698c5c164",
   "metadata": {},
   "source": [
    "### III. Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd8ecf-3739-4cbe-9013-df3cf0c0f87e",
   "metadata": {},
   "source": [
    "#### III.i. Germany Cars Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d54fd9-fdab-4b47-b65f-4af733a34622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing the required parameter `owner_slug` when calling `metadata_get`\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "kaggle_username = \"imaroli\"\n",
    "kaggle_API_key = \"2b5b6a802b9da9c80ca80a25e8e303ad\"\n",
    "\n",
    "!kaggle datasets download -d titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a99d94-2a62-4661-92a4-f981b889bbb6",
   "metadata": {},
   "source": [
    "#### III.ii. Webscrapping UK Office of National Statistics (ONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d3274-a512-413d-83d7-2e5e15c975af",
   "metadata": {},
   "source": [
    "##### III.ii.a Unemployment rate and CPIH (time series economic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25aaf25-97af-45fa-a3e0-11ed7d957874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function for webscrapping data from the UK Office of National Statistics\n",
    "def webscrape_ONS(url):\n",
    "    '''\n",
    "    This function webscrapes various tables from the UK ONS and seperates the data \n",
    "    into distinct dataframes based on the given periodicity: year, quarter, or month.\n",
    "    ----------\n",
    "    Args:\n",
    "        url: The UK Office of National Statistics url from which to webscrabe the table\n",
    "    ----------\n",
    "    Returns:        \n",
    "        ons_year_df: Dataframe of UK ONS data at the yearly level\n",
    "        ons_quarter_df: Dataframe of UK ONS data at the quarterly level\n",
    "        ons_month_df: Dataframe of UK ONS data at the monthly level\n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    # Save the table headers to later set as column names for the dataframes\n",
    "    table_headers = soup.find_all(\"th\")\n",
    "    table_headers = table_headers[0:2] # We only need the first two columns of data from the ONS\n",
    "    table_headers = [t.text for t in table_headers]\n",
    "\n",
    "    ons_data = []\n",
    "\n",
    "    # Identify and append all webscrapped rows of the ONS table into a dataframe\n",
    "    for i, row in enumerate(soup.find_all(\"tr\")[2:]): # The frist two rows of ONS tables are headers\n",
    "        try:\n",
    "            period, value = row.find_all(\"td\")[0:2] # We only need the first two columns of data from the ONS\n",
    "            ons_data.append([period.text, value.text])\n",
    "        except:\n",
    "            print(\"Error parsing row #{}\".format(i))\n",
    "\n",
    "    ons_df = pd.DataFrame(ons_data, columns = table_headers)\n",
    "\n",
    "    # Make the \"Value\" column data type float instead of string as it was webscrapped\n",
    "    ons_df = ons_df.astype({\"Value\": float})\n",
    "\n",
    "    # Split the data into separate dataframes based on periodicity (year/quarter/month)\n",
    "    ons_year_df = ons_df[ons_df[\"Period\"].str.len() == 4].reset_index(drop = True) # Year periods will have 4 characters (e.g., \"2020\")\n",
    "    ons_quarter_df = ons_df[ons_df[\"Period\"].str.len() == 7].reset_index(drop = True) # Quarter periods will have 7 characters (e.g., \"2020 Q1\")\n",
    "    ons_month_df = ons_df[ons_df[\"Period\"].str.len() == 8].reset_index(drop = True) # Month periods will have 8 characters (e.g., \"2020 JAN\")\n",
    "\n",
    "    # For dataframes at the yearly level, make year an int type instead of string as it was webscrapped\n",
    "    ons_year_df = ons_year_df.astype({\"Period\": int})\n",
    "    \n",
    "    # Ensure that all rows present in the original ONS table are present in the three dataframes split based on periodicity\n",
    "    split_df_len = sum([len(ons_year_df), len(ons_quarter_df), len(ons_month_df)])\n",
    "    orig_df_len = len(ons_data)\n",
    "    assert split_df_len == orig_df_len, \"ERROR: Not all rows from original ONS table present in corresponding year/quarter/month dataframes\"\n",
    "\n",
    "    return ons_year_df, ons_quarter_df, ons_month_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775f5de9-3fd2-4334-984c-7ed07896f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrape UK unemployment and CPIH data tables from the ONS\n",
    "url_uk_unemp = \"https://www.ons.gov.uk/employmentandlabourmarket/peoplenotinwork/unemployment/timeseries/mgsx/lms\"\n",
    "url_uk_cpih = \"https://www.ons.gov.uk/economy/inflationandpriceindices/timeseries/l55o/mm23\"\n",
    "\n",
    "uk_unemp_year_df, uk_unemp_quarter_df, uk_unemp_month_df = webscrape_ONS(url_uk_unemp)\n",
    "uk_cpih_year_df, uk_cpih_quarter_df, uk_cpih_month_df = webscrape_ONS(url_uk_cpih)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfe0b46e-3d1e-43ad-b690-c4121d7d0477",
   "metadata": {},
   "source": [
    "Quote on what CPIH entails: https://moneyweek.com/economy/inflation/605602/cpi-inflation-vs-rpi-inflation#:~:text=CPIH%20is%20another%20related%20measure,and%20living%20in%20a%20home.\n",
    "\n",
    "\"CPIH is another related measure calculated by the ONS. It stands for the Consumer Prices Index including owner occupiersâ€™ housing costs. It came in at 3.2% in October.\n",
    "\n",
    "CPIH is similar to CPI, but includes the costs of owning, maintaining and living in a home. This means it also shares characteristics with RPI.\n",
    "\n",
    "CPIH is the ONS's best measure of UK inflation given it captures more of the economy than the other two measures. However, given the UK housing system is different to that of any other nation, it is not internationally comparable.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd63e2a-c1e9-4e73-ba4d-bb2943c63fbc",
   "metadata": {},
   "source": [
    "##### III.ii.b Gross Disposable Household Income (geographic economic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1c14f7-3afd-4e18-9a1f-52ee6c0af926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrape data from the UK Office of National Statistics -- Gross Disposable Household Income (GDHI)\n",
    "url_uk_gdhi = \"https://www.ons.gov.uk/economy/regionalaccounts/grossdisposablehouseholdincome/bulletins/regionalgrossdisposablehouseholdincomegdhi/1997to2022\"\n",
    "\n",
    "page = requests.get(url_uk_gdhi)\n",
    "soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "# Save the table headers to later set as column names for the dataframes\n",
    "table_headers = soup.find_all(\"th\")\n",
    "table_headers = [t.text for t in table_headers]\n",
    "uk_countries_regions_df = pd.DataFrame(table_headers[8:22]) # The data of the 1st column (\"Counties and regions of the UK\") is defined as <th> as opposed to <td> and will be combined with rest of data later\n",
    "table_headers = table_headers[0:5] # We only need the first five columns of data from the ONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15dea661-bae2-465e-9e3e-e4b67c7726ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdhi_data = []\n",
    "\n",
    "# Identify and append all webscrapped rows of the ONS table into a dataframe\n",
    "# The ONS table of interest is: Table 1: Gross disposable household income by UK and constituent countries and regions, UK, 2022\n",
    "# NOTE: 2022 is the most recent year available for ONS data on this topic, this statistical bulletin was released on September 4, 2024\n",
    "for i, row in enumerate(soup.find_all(\"tr\")[1:15]): # The first row of the ONS tables is headers; Table 1 contains 14 rows\n",
    "    try:\n",
    "        pop, gdhi, gdhi_growth, gdhi_index = row.find_all(\"td\")[0:4] # We only need the first four columns of data from the ONS as the 1st column (\"Counties and regions of the UK\") is defined as <th> as opposed to <td> and will be combined later\n",
    "        gdhi_data.append([pop.text, gdhi.text, gdhi_growth.text, gdhi_index.text])\n",
    "    except:\n",
    "        print(\"Error parsing row #{}\".format(i))\n",
    "\n",
    "partial_df = pd.DataFrame(gdhi_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910726cd-cfde-41b6-b071-8d289e081057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the UK countries and regions with the rest of the GDHI data\n",
    "uk_gdhi_df = pd.concat([uk_countries_regions_df, partial_df], axis = 1)\n",
    "uk_gdhi_df.columns = table_headers\n",
    "\n",
    "# Clean the UK GDHI data\n",
    "uk_gdhi_df.rename({\"Countriesandregions of the UK\": \"Countries and regions of the UK\",\n",
    "                   \"Population(million)\": \"Population (million)\",\n",
    "                   \"GDHI perhead (Â£)\": \"GDHI per head (Â£)\"},\n",
    "                  axis = \"columns\",\n",
    "                  inplace = True)\n",
    "uk_gdhi_df[\"GDHI per head (Â£)\"] = uk_gdhi_df[\"GDHI per head (Â£)\"].str.replace(\",\", \"\")\n",
    "uk_gdhi_df = uk_gdhi_df.astype({\"Population (million)\": float, \"GDHI per head (Â£)\": int, \"Growth in GDHI per head (%)\": float, \"GDHI per head index (UK=100)\": float})\n",
    "uk_gdhi_df.replace(\"NorthernIreland\", \"Northern Ireland\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4591259b-f59e-4fa4-858b-f3d4a2b82ee7",
   "metadata": {},
   "source": [
    "#### III.iii. Importing UK Office of National Statistics XLSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bad0d6-047a-447b-a70e-e7230fb33d6e",
   "metadata": {},
   "source": [
    "##### III.iii.a Median gross weekly earnings (geographic economic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8553ee-af55-41fe-a4b8-8b390b2114a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XLSX from the UK Office of National Statistics -- Figure 6: Median gross weekly earnings for full-time employees for all local authorities by place of work \n",
    "# NOTE: This XLSX is provided via download from the following ONS statistical bulletin, \"Employee earnings in the UK: 2024\"\n",
    "    # https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/bulletins/annualsurveyofhoursandearnings/2024\n",
    "ons_weekly_earnings_df = pd.read_excel(\"ONS_figure6.xlsx\", skiprows = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2ba1ae-e2f1-463e-9f30-00ac25b7688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the UK weekly earnings data\n",
    "earnings = ons_weekly_earnings_df[\"Earnings\"]\n",
    "earnings_numeric = pd.to_numeric(earnings, errors = \"coerce\")\n",
    "ons_without_earnings = ons_weekly_earnings_df.drop(columns = \"Earnings\")\n",
    "\n",
    "uk_weekly_earnings_df = pd.concat([ons_without_earnings, earnings_numeric], axis = 1)\n",
    "uk_weekly_earnings_df.dropna(inplace = True, ignore_index = True)\n",
    "uk_weekly_earnings_df[\"Local authority name\"] = uk_weekly_earnings_df[\"Local authority name\"].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a6c25-aa77-464b-b33a-0a2bc0e29c75",
   "metadata": {},
   "source": [
    "#### III.iv. US Bureau of Labor Statistics (BLS) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1654855d-5b5c-484c-ab41-7c34dfaea84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the BLS API for the following two datasets between the years of 2019-2024\n",
    "    # LNS14000000: The USA U-3 unemployment rate (\"official rate\"); civilian unemployment rate for 16 years and older, seasonally adjusted\n",
    "        # https://data.bls.gov/timeseries/LNS14000000\n",
    "    # CUUR0000SA0: CPI - All items in U.S. city average, all urban consumers, not seasonally adjusted\n",
    "        # https://data.bls.gov/timeseries/CUUR0000SA0\n",
    "# We are interested in retaining the last 5 years (2020-2024) of data. The reason for including 2019, is so that we can compute the YoY CPI percentage change\n",
    "# NOTE: because we have not registered we can only querry this API 25 times per day\n",
    "headers = {'Content-type': 'application/json'}\n",
    "data = json.dumps({\"seriesid\": ['LNS14000000', 'CUUR0000SA0'], \"startyear\": \"2019\", \"endyear\": \"2024\"})\n",
    "p = requests.post('https://api.bls.gov/publicAPI/v1/timeseries/data/', data = data, headers = headers)\n",
    "json_data = json.loads(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5273416a-1b5b-4aad-b24c-de778aa4c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the BLS unemployment and CPI data within a dataframe\n",
    "bls_data = []\n",
    "\n",
    "# NOTE: this code is heavily derived from the BLS API Version 1.0 Python Sample Code\n",
    "    # https://www.bls.gov/developers/api_python.htm\n",
    "for series in json_data['Results']['series']:\n",
    "    seriesId = series['seriesID']\n",
    "    for item in series['data']:\n",
    "        year = item['year']\n",
    "        period = item['period']\n",
    "        value = item['value']\n",
    "\n",
    "        if 'M01' <= period <= 'M12':\n",
    "            bls_data.append([seriesId,year,period,value])\n",
    "\n",
    "bls_df = pd.DataFrame(bls_data, columns = [\"SeriesID\", \"Year\", \"Period\", \"Value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d841970-b62c-46d4-a595-4b555b0d103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate BLS table into unemployment and CPI dataframes\n",
    "unemp_df = bls_df[bls_df[\"SeriesID\"] == \"LNS14000000\"].reset_index(drop = True)\n",
    "cpi_df = bls_df[bls_df[\"SeriesID\"] == \"CUUR0000SA0\"].reset_index(drop = True)\n",
    "\n",
    "# Ensure that all rows present in the original BLS table are present in the two split unemployment and CPI dataframes\n",
    "split_df_len = sum([len(unemp_df), len(cpi_df)])\n",
    "orig_df_len = len(bls_df)\n",
    "assert split_df_len == orig_df_len, \"ERROR: Not all rows from original BLS table present in corresponding unemployment and CPI dataframes\"\n",
    "\n",
    "# Clean the BLS unemployment data\n",
    "unemp_df.drop(\"SeriesID\", axis = 1, inplace = True)\n",
    "unemp_df = unemp_df.astype({\"Year\": int, \"Value\": float})\n",
    "\n",
    "# Clean the BLS CPI data\n",
    "cpi_df.drop(\"SeriesID\", axis = 1, inplace = True)\n",
    "cpi_df = cpi_df.astype({\"Year\": int, \"Value\": float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6394e929-e923-4236-8964-4214386b6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in the previous 5 years of US BLS unemployment data (this is at the monthly level)\n",
    "us_unemp_month_df = unemp_df[unemp_df[\"Year\"] > 2019].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b91425-feb9-4eb4-af5b-261c6894094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure BLS CPI data to compute year-over-year values\n",
    "cpi_df_wide = cpi_df.pivot(index = \"Year\", columns = \"Period\", values = \"Value\").pct_change(fill_method = None).reset_index()\n",
    "cpi_df_long = pd.melt(cpi_df_wide, id_vars = [\"Year\"], value_vars = [\"M01\", \"M02\", \"M03\", \"M04\", \"M05\", \"M06\", \"M07\", \"M08\", \"M09\", \"M10\", \"M11\", \"M12\"])\n",
    "\n",
    "# We are only interested in the previous 5 years of US BLS CPI data (this is at the monthly level)\n",
    "us_cpi_month_df = cpi_df_long.dropna().reset_index(drop = True)\n",
    "us_cpi_month_df[\"Value\"] = us_cpi_month_df[\"value\"] * 100\n",
    "us_cpi_month_df.drop(\"value\", axis = 1, inplace = True)\n",
    "us_cpi_month_df = us_cpi_month_df.sort_values([\"Year\", \"Period\"], ascending = False).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0fb56-5ba7-4f25-afa4-df17f1e86799",
   "metadata": {},
   "source": [
    "### IV. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a9d87-6a71-48b5-9ea3-72f7b1f18a58",
   "metadata": {},
   "source": [
    "#### Current datasets that we have:\n",
    "\n",
    "UK national unemployment data at the year (1971-2023), quarter (1971Q1-2023Q3), and month (1971FEB-2024SEP) level. <br>\n",
    "Webscrapped from UK Office of National Statistics: https://www.ons.gov.uk/employmentandlabourmarket/peoplenotinwork/unemployment/timeseries/mgsx/lms <br>\n",
    "**uk_unemp_year_df**, **uk_unemp_quarter_df**, **uk_unemp_month_df**\n",
    "\n",
    "UK national CPIH data at the year (1989-2024), quarter (1989Q1-2024Q4), and month (1989JAN-2024DEC) level. <br>\n",
    "Webscrapped from UK Office of National Statistics: https://www.ons.gov.uk/economy/inflationandpriceindices/timeseries/l55o/mm23 <br>\n",
    "**uk_cpih_year_df**, **uk_cpih_quarter_df**, **uk_cpih_month_df**\n",
    "\n",
    "UK and constituent countries and regions 2022 Gross Disposable Household Income (GDHI) by country/region. <br>\n",
    "Webscrapped data from the UK Office of National Statistics: https://www.ons.gov.uk/economy/regionalaccounts/grossdisposablehouseholdincome/bulletins/regionalgrossdisposablehouseholdincomegdhi/1997to2022 <br>\n",
    "**uk_gdhi_df**\n",
    "\n",
    "Great Britain, April 2024, median gross weekly earnings for full-time employees for all local authorities by place of work. <br>\n",
    "Import XLSX associated with \"Figure 6: Median gross weekly earnings for full-time employees for all local authorities by place of work\" provided for download by the UK Office of National Statistics: https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/bulletins/annualsurveyofhoursandearnings/2024 <br>\n",
    "**uk_weekly_earnings_df**\n",
    "\n",
    "USA monthly (January 2020 - December 2024) U-3 unemployment rate (\"official rate\"); civilian unemployment rate for 16 years and older, seasonally adjusted. <br>\n",
    "Called from the US Bureau of Labor Statistics (BLS) API for the following timeseries (LNS14000000):\n",
    "https://data.bls.gov/timeseries/LNS14000000 <br>\n",
    "**us_unemp_month_df**\n",
    "\n",
    "USA monthly (January 2020 - December 2024) year-over-year percentage change for CPI - All items in U.S. city average, all urban consumers, not seasonally adjusted. <br>\n",
    "Called from the US Bureau of Labor Statistics (BLS) API for the following timeseries (CUUR0000SA0):\n",
    "https://data.bls.gov/timeseries/CUUR0000SA0 <br>\n",
    "**us_cpi_month_df**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55bb0f79-3825-4034-be04-27360a6955f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and merge datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a9d01-0703-4251-b108-c4a8ae9601b2",
   "metadata": {},
   "source": [
    "### V. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f89a6-87ef-48d3-9213-46f2fd3813a6",
   "metadata": {},
   "source": [
    "[[Description of what visualizations we decided to include and why]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2189e31b-d035-4aa3-9d7c-b23607a1e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc481e82-e40a-452c-9beb-9be59b4445da",
   "metadata": {},
   "source": [
    "[[Explanation/interpretation of the visualizations are depicting]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bc21b-107e-44fd-82f0-29a33415595b",
   "metadata": {},
   "source": [
    "### VI. Data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f8b78-c8a2-41c7-b185-410741ebb525",
   "metadata": {},
   "source": [
    "### VII. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dec5a6-42e8-437e-a2e3-54d242af6a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
